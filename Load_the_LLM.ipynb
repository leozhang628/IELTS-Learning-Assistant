{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Load the LLM**"
      ],
      "metadata": {
        "id": "4xjBvWY1VhxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "CrvHhiP8V75t",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e4c43c-49a3-4f8b-97ef-7f6aaf25b9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch<3,>=2.0->bitsandbytes) (79.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"\")"
      ],
      "metadata": {
        "id": "fzmsWcT5ViGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers.utils import is_flash_attn_2_available\n",
        "\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "use_quantization_config = False\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                         bnb_4bit_compute_dtype=torch.float16)\n",
        "\n",
        "\n",
        "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
        "  attn_implementation = \"flash_attention_2\"\n",
        "else:\n",
        "  attn_implementation = \"sdpa\"\n",
        "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
        "\n",
        "# 2. Pick a model we'd like to use (this will depend on how much GPU memory you have available)\n",
        "#model_id = \"google/gemma-7b-it\"\n",
        "model_id = model_id # (we already set this above)\n",
        "print(f\"[INFO] Using model_id: {model_id}\")\n",
        "\n",
        "# 3. Instantiate tokenizer (tokenizer turns text into numbers ready for the model)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
        "\n",
        "# 4. Instantiate the model\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id,\n",
        "                                                 torch_dtype=torch.float16, # datatype to use, we want float16\n",
        "                                                 quantization_config=quantization_config if use_quantization_config else None,\n",
        "                                                 low_cpu_mem_usage=False, # use full memory\n",
        "                                                 attn_implementation=attn_implementation) # which attention version to use\n",
        "\n",
        "if not use_quantization_config: # quantization takes care of device setting automatically, so if it's not used, send model to GPU\n",
        "    llm_model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "9rECNGZ-Vo1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've got an LLM!\n",
        "\n",
        "Let's check it out."
      ],
      "metadata": {
        "id": "CqhKtmf_XHFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model"
      ],
      "metadata": {
        "id": "FDTz85LtXI6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba4d8d2-5bdd-4ee1-9e96-bfbf09d22f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GemmaForCausalLM(\n",
              "  (model): GemmaModel(\n",
              "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-17): 18 x GemmaDecoderLayer(\n",
              "        (self_attn): GemmaAttention(\n",
              "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "        )\n",
              "        (mlp): GemmaMLP(\n",
              "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
              "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
              "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
              "          (act_fn): GELUActivation()\n",
              "        )\n",
              "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
              "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
              "    (rotary_emb): GemmaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we get the number of parameters in our model?"
      ],
      "metadata": {
        "id": "JKcW3pu-XQe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_num_params(model: torch.nn.Module):\n",
        "    return sum([param.numel() for param in model.parameters()])\n",
        "\n",
        "get_model_num_params(llm_model)"
      ],
      "metadata": {
        "id": "ZtUPHXoAXPzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00ba5f7-ca8d-4f3f-c223-007e053f1010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2506172416"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Generating text with our LLM(gemma)**"
      ],
      "metadata": {
        "id": "-0pnXKNPXcMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"how can I improve speaking skills\"\n",
        "print(f\"Input text:\\n{input_text}\")\n",
        "\n",
        "# Create prompt template for instruction-tuned model\n",
        "dialogue_template = [\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": input_text}\n",
        "]\n",
        "\n",
        "# Apply the chat template\n",
        "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                       tokenize=False, # keep as raw text (not tokenized)\n",
        "                                       add_generation_prompt=True)\n",
        "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
      ],
      "metadata": {
        "id": "YUWT-ymiXgrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30729e77-08b0-4573-da6b-bd3e5fa300de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text:\n",
            "how can I improve speaking skills\n",
            "\n",
            "Prompt (formatted):\n",
            "<bos><start_of_turn>user\n",
            "how can I improve speaking skills<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
        "\n",
        "# Generate outputs passed on the tokenized input\n",
        "outputs = llm_model.generate(**input_ids,\n",
        "                             max_new_tokens=256) # define the maximum number of new tokens to create\n",
        "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
      ],
      "metadata": {
        "id": "cus2lrXWXpcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4194a5-857b-45f6-9f9e-e08619da2a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input (tokenized):\n",
            "{'input_ids': tensor([[    2,     2,   106,  1645,   108,  1139,   798,   590,  4771, 13041,\n",
            "          7841,   107,   108,   106,  2516,   108]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "\n",
            "Model output (tokens):\n",
            "tensor([     2,      2,    106,   1645,    108,   1139,    798,    590,   4771,\n",
            "         13041,   7841,    107,    108,    106,   2516,    108,    688, 235274,\n",
            "        235265,  19670, 186522,  66058,    108, 235290, 100922,    575,  30893,\n",
            "           675,  11634,  22660,    689,   6016,    675,    476,   5255,   9670,\n",
            "        235265,    108, 235290,  20470,    476,   5255,  10036,   2778,    689,\n",
            "          3650,  16875, 235265,    108, 235290,  15940,   5804,  13041,    578,\n",
            "         10724,   1355,    577,  11441,   4516,    604,  13194, 235265,    109,\n",
            "           688, 235284, 235265,  26349,    611,  58212,  42535,  66058,    108,\n",
            "        235290,   8138,   6137,    577,    573,   9788,    576,    573,   5255,\n",
            "        235269,   3359, 187457, 235269,  36168, 235269,    578,   7512, 235265,\n",
            "           108, 235290,   5362,  74569,   8112,    578,  48363,    577,   3918,\n",
            "          5112,  74569, 235265,    108, 235290,  19670,  13041,   3907,    578,\n",
            "         35070,    921,  16129, 235269,  28643,    611,   2167,  65359, 235265,\n",
            "           109,    688, 235304, 235265,  77868,   3883,  84950,  66058,    108,\n",
            "        235290,   4814,  44224,    575,    573,   4408,   5255, 235269,   2145,\n",
            "         26922,    578,   2173, 235290,  44557, 235265,    108, 235290,  35170,\n",
            "           577,  76274, 235269, 231523, 235269,    578,   4296,    575,    573,\n",
            "          5255, 235265,    108, 235290,   5362, 168402,    578,  70090,  53304,\n",
            "         10423,    577,   3918,    888,   3907, 235265,    109,    688, 235310,\n",
            "        235265,   4814,  14495,   2752,  66058,    108, 235290,   7248,    675,\n",
            "          3069, 235303, 235256,   6142,    689,   3890,  26448,    578,  20914,\n",
            "          7695,    577,    978,   5766,   6205, 235265,    108, 235290,   8138,\n",
            "          6137,    577,  33342, 235269,  94152, 235269,    578,  13060,   5449,\n",
            "        235265,    108, 235290,   5362,    476,  25730,    578,    573, 118687,\n",
            "           577,   1717, 120352,    578,   4891,  36457, 235265,    109,    688,\n",
            "        235308, 235265,   5362,  20798, 113230,  66058,    108, 235290,   5362,\n",
            "        168402, 235269,  44816, 235269,    578,   1156,   9095,  43464,    577,\n",
            "          2676,    861,  22230,   5255, 235265,    108, 235290,  13466,  14554,\n",
            "           578,   5607,   4918,    675,  99013,    577,   4771,  61516,    578,\n",
            "         74569, 235265,    109,    688, 235318, 235265,  15940,    578,  73763,\n",
            "         66058,    108], device='cuda:0')\n",
            "\n",
            "CPU times: user 7.58 s, sys: 93.3 ms, total: 7.68 s\n",
            "Wall time: 7.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the output tokens to text\n",
        "outputs_decoded = tokenizer.decode(outputs[0])\n",
        "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
      ],
      "metadata": {
        "id": "CalUd3pcYMnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242d8189-4720-476d-a836-8b49b8a068fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output (decoded):\n",
            "<bos><bos><start_of_turn>user\n",
            "how can I improve speaking skills<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**1. Practice Regularly:**\n",
            "- Engage in conversations with native speakers or practice with a language partner.\n",
            "- Join a language exchange group or online forum.\n",
            "- Record yourself speaking and listen back to identify areas for improvement.\n",
            "\n",
            "**2. Focus on Pronunciation:**\n",
            "- Pay attention to the sounds of the language, including intonation, rhythm, and stress.\n",
            "- Use pronunciation tools and recordings to learn correct pronunciation.\n",
            "- Practice speaking words and phrases out loud, focusing on different accents.\n",
            "\n",
            "**3. Expand Your Vocabulary:**\n",
            "- Read extensively in the target language, both fiction and non-fiction.\n",
            "- Listen to podcasts, audiobooks, and music in the language.\n",
            "- Use flashcards and spaced repetition techniques to learn new words.\n",
            "\n",
            "**4. Read Fluently:**\n",
            "- Start with children's books or simple texts and gradually progress to more complex materials.\n",
            "- Pay attention to grammar, punctuation, and sentence structure.\n",
            "- Use a dictionary and thesaurus to find synonyms and antonyms.\n",
            "\n",
            "**5. Use Visual Aids:**\n",
            "- Use flashcards, diagrams, and other visual aids to support your spoken language.\n",
            "- Watch movies and TV shows with subtitles to improve comprehension and pronunciation.\n",
            "\n",
            "**6. Record and Reflect:**\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input text: {input_text}\\n\")\n",
        "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
      ],
      "metadata": {
        "id": "AOLj6f53Y6QV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12bab867-5827-41c1-92c2-44b0db27fc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: how can I improve speaking skills\n",
            "\n",
            "Output text:\n",
            "**1. Practice Regularly:**\n",
            "- Engage in conversations with native speakers or practice with a language partner.\n",
            "- Join a language exchange group or online forum.\n",
            "- Record yourself speaking and listen back to identify areas for improvement.\n",
            "\n",
            "**2. Focus on Pronunciation:**\n",
            "- Pay attention to the sounds of the language, including intonation, rhythm, and stress.\n",
            "- Use pronunciation tools and recordings to learn correct pronunciation.\n",
            "- Practice speaking words and phrases out loud, focusing on different accents.\n",
            "\n",
            "**3. Expand Your Vocabulary:**\n",
            "- Read extensively in the target language, both fiction and non-fiction.\n",
            "- Listen to podcasts, audiobooks, and music in the language.\n",
            "- Use flashcards and spaced repetition techniques to learn new words.\n",
            "\n",
            "**4. Read Fluently:**\n",
            "- Start with children's books or simple texts and gradually progress to more complex materials.\n",
            "- Pay attention to grammar, punctuation, and sentence structure.\n",
            "- Use a dictionary and thesaurus to find synonyms and antonyms.\n",
            "\n",
            "**5. Use Visual Aids:**\n",
            "- Use flashcards, diagrams, and other visual aids to support your spoken language.\n",
            "- Watch movies and TV shows with subtitles to improve comprehension and pronunciation.\n",
            "\n",
            "**6. Record and Reflect:**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation."
      ],
      "metadata": {
        "id": "83ms8e7ya_cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IELTS-style questions generated with GPT-4\n",
        "gpt4_questions = [\n",
        "    \"What are the best strategies to improve your IELTS speaking score?\",\n",
        "    \"How can you effectively manage time during the IELTS reading test?\",\n",
        "    \"Describe techniques to write a high-scoring IELTS essay.\",\n",
        "    \"What role does vocabulary play in the IELTS listening section?\",\n",
        "    \"Explain the importance of practicing mock tests for the IELTS exam.\",\n",
        "    \"How can you build fluency for the IELTS speaking test?\",\n",
        "]\n",
        "\n",
        "# Manually created question list\n",
        "manual_questions = [\n",
        "    \"What are common mistakes to avoid in the IELTS writing task?\",\n",
        "    \"How should you prepare for the IELTS listening section?\",\n",
        "    \"What is the ideal structure for an IELTS Task 2 essay?\",\n",
        "    \"What are the key differences between IELTS Academic and General Training?\",\n",
        "    \"How can you improve your band score in the IELTS reading test?\",\n",
        "]\n",
        "\n",
        "# Combine GPT-4 generated and manually created questions\n",
        "query_list = gpt4_questions + manual_questions"
      ],
      "metadata": {
        "id": "NvO5OslGa_7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let's check if our `retrieve_relevant_resources()` function works with our list of queries."
      ],
      "metadata": {
        "id": "rF-UKnpub6i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "query = random.choice(query_list)\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Get just the scores and indices of top related results\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "scores, indices"
      ],
      "metadata": {
        "id": "hNxLsPs4b6_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbc27f1-495b-406b-faa0-7202d4d40407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are common mistakes to avoid in the IELTS writing task?\n",
            "[INFO] Time taken to get scores on 30 embeddings: 0.00009 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.4694, 0.4677, 0.4606, 0.4605, 0.4586], device='cuda:0'),\n",
              " tensor([12, 23,  4, 17,  0], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Augmenting our prompt with context items**"
      ],
      "metadata": {
        "id": "ovC3lfbZcgp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_formatter(query: str, context_items: list[dict]) -> str:\n",
        "    \"\"\"\n",
        "    Augments query with text-based context from context_items.\n",
        "    \"\"\"\n",
        "    # Join context items into a single paragraph\n",
        "    context = \"\\n\\n\".join([item[\"sentence_chunk\"] for item in context_items])\n",
        "\n",
        "    # Create the improved base prompt\n",
        "    base_prompt = f\"\"\"Based on the following context items, provide the most helpful and detailed answer to the query below.\n",
        "    If you cannot find relevant information in the provided context, use your general knowledge and logical reasoning to generate a well-informed, accurate, and practical answer.\n",
        "    Ensure that your response remains factual, logical, and does not speculate beyond reasonable assumptions.\n",
        "\n",
        "    Before generating the final answer, show your thought process step by step. These steps should include:\n",
        "    1. Identifying relevant information from the provided context (if available).\n",
        "    2. Explaining how the context or your reasoning is applied to answer the query.\n",
        "    3. Highlighting any assumptions made if the context is insufficient.\n",
        "\n",
        "    Finally, provide your answer in a clear and concise manner. Use the following examples as a reference for the ideal answer style. Your answer should not include the examples themselves, only follow their structure and tone.\n",
        "\n",
        "    Example 1:\n",
        "    Query: What are the best strategies to improve your IELTS speaking score?\n",
        "    Answer: To improve your IELTS speaking score, focus on fluency and coherence by practicing speaking with friends or recording yourself and listening for areas of improvement. Expand your vocabulary by learning phrases and idioms relevant to common IELTS topics, such as education, environment, and technology. Additionally, practice answering past IELTS speaking questions under timed conditions to simulate the test environment.\n",
        "\n",
        "    Example 2:\n",
        "    Query: How can you effectively manage time during the IELTS reading test?\n",
        "    Answer: To manage time effectively during the IELTS reading test, start by quickly skimming the passage to get a general idea of its content. Then, read the questions and underline key information. Divide your time equally across the three sections, spending no more than 20 minutes per section. If you encounter difficult questions, move on and return to them later if time permits.\n",
        "\n",
        "    Example 3:\n",
        "    Query: What is the ideal structure for an IELTS Writing Task 2 essay?\n",
        "    Answer: A high-scoring IELTS Writing Task 2 essay should include an introduction that clearly states your position, two or three body paragraphs with arguments supported by examples, and a conclusion that summarizes your key points. Ensure coherence and cohesion by using linking words such as \"however,\" \"therefore,\" and \"in addition.\" Also, proofread your essay to avoid grammatical mistakes and spelling errors.\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Query: {query}\n",
        "\n",
        "    Explain your thought process step by step:\n",
        "    1. ...\n",
        "    2. ...\n",
        "    3. ...\n",
        "\n",
        "    Final Answer:\"\"\"\n",
        "\n",
        "    # Update the base prompt with context items and query\n",
        "    dialogue_template = [\n",
        "        {\"role\": \"user\", \"content\": base_prompt}\n",
        "    ]\n",
        "\n",
        "    # Generate the prompt\n",
        "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                          tokenize=False,\n",
        "                                          add_generation_prompt=True)\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "ieD0LrCgchGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try our function out."
      ],
      "metadata": {
        "id": "v2ycKD7keG8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = random.choice(query_list)\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Get relevant resources\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "\n",
        "# Create a list of context items\n",
        "context_items = [pages_and_chunks[i] for i in indices]\n",
        "\n",
        "# Format prompt with context items\n",
        "prompt = prompt_formatter(query=query,\n",
        "                          context_items=context_items)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "vJ9vREqYeHSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f302ec09-86a4-4598-b024-40a071ac96a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are the key differences between IELTS Academic and General Training?\n",
            "[INFO] Time taken to get scores on 30 embeddings: 0.00008 seconds.\n",
            "<bos><start_of_turn>user\n",
            "Based on the following context items, provide the most helpful and detailed answer to the query below.\n",
            "    If you cannot find relevant information in the provided context, use your general knowledge and logical reasoning to generate a well-informed, accurate, and practical answer.\n",
            "    Ensure that your response remains factual, logical, and does not speculate beyond reasonable assumptions.\n",
            "\n",
            "    Before generating the final answer, show your thought process step by step. These steps should include:\n",
            "    1. Identifying relevant information from the provided context (if available).\n",
            "    2. Explaining how the context or your reasoning is applied to answer the query.\n",
            "    3. Highlighting any assumptions made if the context is insufficient.\n",
            "\n",
            "    Finally, provide your answer in a clear and concise manner. Use the following examples as a reference for the ideal answer style. Your answer should not include the examples themselves, only follow their structure and tone.\n",
            "\n",
            "    Example 1:\n",
            "    Query: What are the best strategies to improve your IELTS speaking score?\n",
            "    Answer: To improve your IELTS speaking score, focus on fluency and coherence by practicing speaking with friends or recording yourself and listening for areas of improvement. Expand your vocabulary by learning phrases and idioms relevant to common IELTS topics, such as education, environment, and technology. Additionally, practice answering past IELTS speaking questions under timed conditions to simulate the test environment.\n",
            "\n",
            "    Example 2:\n",
            "    Query: How can you effectively manage time during the IELTS reading test?\n",
            "    Answer: To manage time effectively during the IELTS reading test, start by quickly skimming the passage to get a general idea of its content. Then, read the questions and underline key information. Divide your time equally across the three sections, spending no more than 20 minutes per section. If you encounter difficult questions, move on and return to them later if time permits.\n",
            "\n",
            "    Example 3:\n",
            "    Query: What is the ideal structure for an IELTS Writing Task 2 essay?\n",
            "    Answer: A high-scoring IELTS Writing Task 2 essay should include an introduction that clearly states your position, two or three body paragraphs with arguments supported by examples, and a conclusion that summarizes your key points. Ensure coherence and cohesion by using linking words such as \"however,\" \"therefore,\" and \"in addition.\" Also, proofread your essay to avoid grammatical mistakes and spelling errors.\n",
            "\n",
            "    Context:\n",
            "    The \r \r \r the chick to leave \r \r and so lend to \r \r \r it again and the \r \r \r experiment had \r \r \r the nest and fly. \r \r be found in and \r \r \r results showed a \r \r \r failed and, as a re$uft, \r \r \r \r around tropica! \r \r \r significant change in \r \r \r the public grew \r \r \r \r rainforests. \r \r \r temperature when the \r \r \r angry at the waste \r \r \r \r \r \r insulation was used. \r \r \r of public funds. \r \r \r \r \r Types of information \r \r 1 the findings of a study \r \r 2 the method used in a research study \r \r 3 the rea ct ion to someth t n g \r \r 4 a description of a habitat \r \r 5 the difference between current and past studies \r \r 6 a description of how something works \r \r 7 the cause of something \r \r 8 the amount of time needed for something \r \r \r 2 Locating and matching information \r \r Just like matching headings, matching information questions are \r not in the same order as the passage. \r \r \r Study Tip Some examples of the type of information you may be \r asked to find are: \r \r * a finding \r \r \r • a number \r ■ a date \r \r • a measurement \r \r • a reason \r \r \r • a cause \r \r « an effect \r \r • a conclusion \r \r • the probfems \r \r \r an account \r a reaction \r a description. \r \r \r When you are reading different passages in this book, think about \r whether the information matches any of these types. \r \r \r 60 \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r Reading skills \r \r \r 2.1 Spend two minutes skim reading ike passage below, so ihai you are \r familiar wiili (he type of information it contains. \r \r What is the main purpose of ihe passage?\n",
            "\n",
            "3.3 Read statements 4-8, then underline ihc relevant parts in the text. Arc the \r statements True, False or Nci Given? \r \r 4 Atiania has experienced more dramatic weather change than other areas of the US. \r \r 5 Roofs that are dark in colour help address the issue of Urban Heat islands. \r \r 6 Singapore's Supenrees are made entirely from natural materials. \r \r 7 The designers of the Supertrees originally planned to plant very tall trees. \r \r 8 The Superirees require regular maintenance. \r \r \r 3.4 Read statements 1-8 again and correct any that were false. \r \r \r 58 \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r information \r \r In this unit you will practise: \r \r • identifying types of information \r \r • locating and matching information \r \r • connecting ideas \r \r • matching sentence endings \r \r • matching information \r \r v**' vv w E1- + 'f m \r \r \r t Identifying types of information \r \r For matching information tasks, you need to locate ail idea or piece of \r information in the texi and match it to a phrase that accurately describes it. \r \r \r 1.1 Read the extracts from two separate paragraphs of a Reading \r passage.\n",
            "\n",
            "61 \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r Reading skills \r \r \r 2.2 Look at tliis task based on (he Reading passage. For each \r \r question, underline the type of information you need to scan Tor. \r The first two have been done for you. \r \r \r Which paragraph contains the following information? \r \r N. B You may use any letter more than once \r \r Write the correct letter. A-E, next to questions 1-7 below, \r \r 1 visual evidence of the gecko's ability to resist water \r \r 2 a question that is yet to be answered by the researchers \r \r 3 the method used to calculate the gripping power of geckos \r \r 4 the researcher's opinion of the gecko’s gripping ability \r \r 5 a mention of the different environments where geckos can be found \r \r 6 the contrast between Stark's research and the work of other researchers \r \r 7 the definition of a scientific term \r \r \r 2.3 It is important to fully understand what you are looking for in \r the passage. Answer these questions, based on Question I in the \r task above, \r \r 1 Which of the following do you think is 'visual evidence’? \r \r A som et hing the re sea re he rs belie ve \r B something the researchers have seen \r C something the researchers have read about \r \r 2 Which of the following means the same as 'ability to resist \r water'? \r \r A soaks up water \r B sinks in water \r C stops water getting in \r \r 3 Scan the passage to find 'visual evidence' of an ability to resist \r water, which paragraph contains this information? \r \r 2.4 Study Questions 2-7 in 2.2 carefully and match them to \r paragraphs A-E. Remember, the questions are not in the same \r order as the passage.\n",
            "\n",
            "You need to \r focus on the whole idea \r of each paragraph. \r \r \r 56 \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r Reading skills \r \r \r 2 Understanding the main points \r \r Another type of question that can fbtus on the main point of a \r paragraph is multiple choice. This type of question often requires \r you to carefully read more ilian one sentence in the paragraph, \r \r 2*1 Look at this question, based on the passage in 1.2. \r \r I In Paragraph A, what is the main point that the writer makes? \r \r A Some urban designs are better in theory than in practice. \r \r 8 The urban-planning concept itself is not restricted to \r modern times. \r \r C Urban planning should be carried out by professionals. \r r> Some planned ancient cities are more successful than \r modern ones. \r \r 2.2 The parte of Paragraph A relating to each option are underlined \r below, Read the paragraph carefully and choose the correct \r option, A-D. \r \r \r 5 The notion pj panning gnbr e.communities Poor to their construction is an ancient on* . ; In fact, one nf tho \r cities pn record is Miletus.\n",
            "\n",
            "[fudging from] the complexity of the material that has been collected from different parts of the landscape \r and brought to the site, they | the people] must have had an elementary knowledge of chemistry to be able to \r combine these materials to produce ibis form. Its not a straightforward process,™ said Henshilwood. \r \r \r 1 *2 Scanning involves searching a text quickly for a specific piece \r of information. Practise scanning the passage for the words/ \r numbers in the box. \r \r \r 75,000 100,000 200,000 artefacts ochre \r \r \r 48 \r \r \r \r \r \r \r \r \r Reading skills \r \r \r 2 Using words from the passage \r \r Their are several types of question that ask you to write a word and/or \r number from the passage. \r \r * You will be told the maximum number of words to write. \r \r * You must only write words that are in the passage. Make sure you \r copy the spelling correctly, \r \r 1 ^ ^ need to change the words in the passage and you do not \r need to join words together. \r \r II um w rite tuo many words or make a spelling mistake, your answer \r wilt he marked wrong. \r \r Test Tip if the question asks you to write TWO WORDS AND/OR A \r NUMBER, this means the answer may be: \r \r * one word \r \r * one word + a number \r ■ two words \r \r * two words + a number \r \r Remember that even if a number is written as a word, it counts as a \r number (e.g. twenty five trees = one word and a number).\n",
            "\n",
            "    Query: What are the key differences between IELTS Academic and General Training?\n",
            "\n",
            "    Explain your thought process step by step:\n",
            "    1. ...\n",
            "    2. ...\n",
            "    3. ...\n",
            "\n",
            "    Final Answer:<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can tokenize this and pass it straight to our LLM."
      ],
      "metadata": {
        "id": "2D4sSDxleRlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate an output of tokens\n",
        "outputs = llm_model.generate(**input_ids,\n",
        "                             temperature=0.7, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\n",
        "                             do_sample=True,\n",
        "                             max_new_tokens=256) # how many new tokens to generate from prompt\n",
        "\n",
        "# Turn the output tokens into text\n",
        "output_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"RAG answer:\\n{output_text.replace(prompt, '')}\")"
      ],
      "metadata": {
        "id": "GilYoyKaeSu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0568df-0667-4b1a-a12b-a7c322beab11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are the key differences between IELTS Academic and General Training?\n",
            "RAG answer:\n",
            "<bos>**Thought Process:**\n",
            "\n",
            "**1. Identifying Relevant Information**\n",
            "\n",
            "* The passage does not provide any directly relevant information about IELTS Academic and General Training, so I cannot identify any key differences between the two programs from the context.\n",
            "\n",
            "**2. Explaining Reasoning**\n",
            "\n",
            "I am unable to generate a response because the context does not provide any information about the key differences between IELTS Academic and General Training.\n",
            "\n",
            "**3. Assumptions Made**\n",
            "\n",
            "The context does not provide any assumptions, so I cannot generate a response.<eos>\n",
            "CPU times: user 3.31 s, sys: 5.68 ms, total: 3.31 s\n",
            "Wall time: 3.31 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we functionize the generation step to make it easier to use?"
      ],
      "metadata": {
        "id": "fFwUIxtlfI4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(query,\n",
        "        temperature=0.7,\n",
        "        max_new_tokens=512,\n",
        "        format_answer_text=True,\n",
        "        return_answer_only=True):\n",
        "    \"\"\"\n",
        "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get just the scores and indices of top related results\n",
        "    scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                                  embeddings=embeddings)\n",
        "\n",
        "    # Create a list of context items\n",
        "    context_items = [pages_and_chunks[i] for i in indices]\n",
        "\n",
        "    # Add score to context item\n",
        "    for i, item in enumerate(context_items):\n",
        "        item[\"score\"] = scores[i].cpu() # return score back to CPU\n",
        "\n",
        "    # Format the prompt with context items\n",
        "    prompt = prompt_formatter(query=query,\n",
        "                              context_items=context_items)\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate an output of tokens\n",
        "    outputs = llm_model.generate(**input_ids,\n",
        "                                 temperature=temperature,\n",
        "                                 do_sample=True,\n",
        "                                 max_new_tokens=max_new_tokens)\n",
        "\n",
        "    # Turn the output tokens into text\n",
        "    output_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "    if format_answer_text:\n",
        "        # Replace special tokens and unnecessary help message\n",
        "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
        "\n",
        "    # Only return the answer without the context items\n",
        "    if return_answer_only:\n",
        "        return output_text\n",
        "\n",
        "    return output_text, context_items"
      ],
      "metadata": {
        "id": "6ldd4z9HfJXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try it out."
      ],
      "metadata": {
        "id": "2_b5Q8H-fQJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random.choice(query_list)"
      ],
      "metadata": {
        "id": "usREzY8stnZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = random.choice(query_list)\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Answer query with context and return context\n",
        "answer, context_items = ask(query=query,\n",
        "                            temperature=0.7,\n",
        "                            max_new_tokens=512,\n",
        "                            return_answer_only=False)\n",
        "\n",
        "print(f\"Answer:\\n\")\n",
        "print_wrapped(answer)\n",
        "# print(f\"Context items:\")\n",
        "#context_items"
      ],
      "metadata": {
        "id": "GoqWop0xfQwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6298907a-8dfa-4b88-9378-5f2d5ccfb52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are the best strategies to improve your IELTS speaking score?\n",
            "[INFO] Time taken to get scores on 30 embeddings: 0.00007 seconds.\n",
            "Answer:\n",
            "\n",
            "## Thought process:  **Step 1: Identifying relevant information**  * The context\n",
            "mentions that improving your IELTS speaking score requires practicing speaking\n",
            "with friends or recording yourself and listening for areas of improvement. * It\n",
            "also suggests learning phrases and idioms relevant to common IELTS topics. *\n",
            "These suggest that practicing speaking in a social setting, learning vocabulary,\n",
            "and being familiar with idiomatic expressions are key strategies for improving\n",
            "speaking skills.  **Step 2: Applying the context**  The context advises\n",
            "practicing speaking with friends, recording yourself, and listening for areas of\n",
            "improvement. It also suggests learning vocabulary and idioms relevant to common\n",
            "IELTS topics.  **Step 3: Assumptions**  * The context does not provide any\n",
            "specific information or guidelines for practicing speaking in a social setting.\n",
            "* The context does not provide any specific information or guidelines for\n",
            "learning vocabulary and idioms.  **Final answer:**  The best strategies to\n",
            "improve your IELTS speaking score are:  1. Practice speaking with friends in a\n",
            "social setting. 2. Learn vocabulary and idioms relevant to common IELTS topics.\n",
            "3. Listen for areas of improvement in your spoken English and practice speaking\n",
            "accordingly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Using the gemma-2b-it model\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "\n",
        "# Loading the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Set chat_template correctly\n",
        "tokenizer.chat_template = \"{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\\\\n' + message['content'] + '\\\\n' }}{% endfor %}\"\n",
        "\n",
        "# Loading the model\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "\n",
        "# Move the model to the GPU (if available)\n",
        "llm_model.to(\"cuda\")\n",
        "\n",
        "print(\"The model and tokenizer were successfully loaded, and the chat_template was set!\")\n"
      ],
      "metadata": {
        "id": "KcME0xQUJNhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Text to speech model(facebook/mms-tts-eng)**"
      ],
      "metadata": {
        "id": "90rpff4kPH_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.51.3 accelerate==1.6.0 --no-warn-script-location --quiet"
      ],
      "metadata": {
        "id": "PjKKCs7XtioN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers accelerate"
      ],
      "metadata": {
        "id": "ynfGrXxPVeOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VitsModel, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
        "\n",
        "text = answer\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(**inputs).waveform\n"
      ],
      "metadata": {
        "id": "J4mOM-XRVeMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(output.numpy(), rate=model.config.sampling_rate)"
      ],
      "metadata": {
        "id": "l9yrJ_1fVeJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io.wavfile import write\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "# Assume `output` is the generated audio data (Tensor) with sampling rate `model.config.sampling_rate`\n",
        "sampling_rate = model.config.sampling_rate\n",
        "output_filename = \"generated_audio.wav\"\n",
        "\n",
        "# 1. Convert audio data to numpy array\n",
        "audio_data = output.numpy()  # 转换为 numpy 数组\n",
        "\n",
        "# 2. Check the range of the audio data and normalize it to [-1.0, 1.0]\n",
        "# If the data range is not [-1.0, 1.0], you need to normalize it first\n",
        "if audio_data.min() < -1.0 or audio_data.max() > 1.0:\n",
        "    audio_data = audio_data / np.max(np.abs(audio_data))  # Normalized to [-1.0, 1.0]\n",
        "\n",
        "# 3. Make sure the audio data is a one-dimensional array (mono)\n",
        "if len(audio_data.shape) > 1:\n",
        "    audio_data = audio_data.squeeze()  # Remove redundant dimensions\n",
        "\n",
        "# 4. Convert data from [-1.0, 1.0] to int16 range [-32768, 32767]\n",
        "audio_data = (audio_data * 32767).astype(np.int16)\n",
        "\n",
        "# 5. Save audio to .wav file\n",
        "write(output_filename, sampling_rate, audio_data)\n",
        "\n",
        "# 6. Download the audio file to your local computer\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "id": "uyoZ6VNiNMYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "734126f2-563c-477c-c2b9-dc41581f4a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c459f7a5-f3d5-402d-9f7d-2de52c2bc919\", \"generated_audio.wav\", 2314284)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)  # Check if the current tokenizer is correct\n",
        "print(hasattr(tokenizer, \"chat_template\"))  # Check if chat_template is set"
      ],
      "metadata": {
        "id": "AmMJnm1tVeGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa7a449f-9b6a-49e2-ea0a-19e20cc9bb41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VitsTokenizer(name_or_path='facebook/mms-tts-eng', vocab_size=38, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '<unk>', 'pad_token': 'k'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
            "\t0: AddedToken(\"k\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t38: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**SoVITS model**"
      ],
      "metadata": {
        "id": "Mj2tTXxGp_R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/setup.sh\n",
        "set -e\n",
        "cd /content\n",
        "rm -rf GPT-SoVITS\n",
        "git clone https://github.com/RVC-Boss/GPT-SoVITS.git\n",
        "cd GPT-SoVITS\n",
        "\n",
        "if conda env list | awk '{print $1}' | grep -Fxq \"GPTSoVITS\"; then\n",
        "    :\n",
        "else\n",
        "    conda create -n GPTSoVITS python=3.10 -y\n",
        "fi\n",
        "\n",
        "source activate GPTSoVITS\n",
        "\n",
        "bash install.sh --source HF --download-uvr5"
      ],
      "metadata": {
        "id": "FfHewNE_p4Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install_from_url(\"https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh\")\n",
        "!cd /content && bash setup.sh"
      ],
      "metadata": {
        "id": "qBO_E3Bop4Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/GPT-SoVITS && source activate GPTSoVITS && export is_share=True && python webui.py"
      ],
      "metadata": {
        "id": "_yYpXYZep4G6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}