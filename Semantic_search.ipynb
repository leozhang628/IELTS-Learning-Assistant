{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Time to perform a semantic search**"
      ],
      "metadata": {
        "id": "rwyGS5KtS8HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util, SentenceTransformer\n",
        "\n",
        "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
        "                                      device=device) # choose the device to load the model to"
      ],
      "metadata": {
        "id": "C1x2csCUTdvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the query\n",
        "# Note: This could be anything. But since we're working with a nutrition textbook, we'll stick with nutrition-based queries.\n",
        "query = \"reading skill\"\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# 2. Embed the query to the same numerical space as the text examples\n",
        "# Note: It's important to embed your query with the same model you embedded your examples with.\n",
        "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "# 3. Get similarity scores with the dot product (we'll time this for fun)\n",
        "from time import perf_counter as timer\n",
        "\n",
        "start_time = timer()\n",
        "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "# 4. Get the top-k results (we'll keep this to 5)\n",
        "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
        "top_results_dot_product"
      ],
      "metadata": {
        "id": "BkflXgdnToeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbdffebe-66f1-4ce3-ad18-457ec2d56aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: reading skill\n",
            "Time take to get scores on 30 embeddings: 0.00833 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(\n",
              "values=tensor([0.5677, 0.5357, 0.5271, 0.5006, 0.4489], device='cuda:0'),\n",
              "indices=tensor([23,  2,  4, 17,  5], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define helper function to print wrapped text\n",
        "import textwrap\n",
        "\n",
        "def print_wrapped(text, wrap_length=80):\n",
        "    wrapped_text = textwrap.fill(text, wrap_length)\n",
        "    print(wrapped_text)"
      ],
      "metadata": {
        "id": "LTeBbEWyTvda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the result!!"
      ],
      "metadata": {
        "id": "S_KxlFP8VO_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Query: '{query}'\\n\")\n",
        "print(\"Results:\")\n",
        "# Loop through zipped together scores and indicies from torch.topk\n",
        "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
        "    print(f\"Score: {score:.4f}\")\n",
        "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
        "    print(\"Text:\")\n",
        "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
        "    # Print the page number too so we can reference the textbook further (and check the results)\n",
        "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "gZYJbuqQUVmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3e2646-a753-46db-de0a-06a93b2c2219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'reading skill'\n",
            "\n",
            "Results:\n",
            "Score: 0.5677\n",
            "Text:\n",
            "61                                       Reading skills       2.2 Look at tliis\n",
            "task based on (he Reading passage. For each     question, underline the type of\n",
            "information you need to scan Tor.   The first two have been done for you.\n",
            "Which paragraph contains the following information?     N. B You may use any\n",
            "letter more than once     Write the correct letter. A-E, next to questions 1-7\n",
            "below,     1 visual evidence of the gecko's ability to resist water     2 a\n",
            "question that is yet to be answered by the researchers     3 the method used to\n",
            "calculate the gripping power of geckos     4 the researcher's opinion of the\n",
            "gecko’s gripping ability     5 a mention of the different environments where\n",
            "geckos can be found     6 the contrast between Stark's research and the work of\n",
            "other researchers     7 the definition of a scientific term       2.3 It is\n",
            "important to fully understand what you are looking for in   the passage. Answer\n",
            "these questions, based on Question I in the   task above,     1 Which of the\n",
            "following do you think is 'visual evidence’?     A som et hing the re sea re he\n",
            "rs belie ve   B something the researchers have seen   C something the\n",
            "researchers have read about     2 Which of the following means the same as\n",
            "'ability to resist   water'?     A soaks up water   B sinks in water   C stops\n",
            "water getting in     3 Scan the passage to find 'visual evidence' of an ability\n",
            "to resist   water, which paragraph contains this information?     2.4 Study\n",
            "Questions 2-7 in 2.2 carefully and match them to   paragraphs A-E. Remember, the\n",
            "questions are not in the same   order as the passage.\n",
            "Page number: nan\n",
            "\n",
            "\n",
            "Score: 0.5357\n",
            "Text:\n",
            "49                                                   Reading skills       2.2\n",
            "Look at the remaining questions, 4-6, Underline the words that   will help you\n",
            "locale the information in the passage and highlight   the details you need to\n",
            "find. Then answer the questions.     4 What did the ancient people use to keep\n",
            "their ochre mixture in?     5 Nowadays, who makes use of ochre?     6 Apart from\n",
            "painting, what else might ancient humans have used ochre for?       3\n",
            "Notes/flow-chart/diagram completion     The questions in 3.] all focus on\n",
            "paraphrase. Paraphrase is the use of   different words with the same meaning.\n",
            "This helps to test how much   of the Reading passage you understand.     3.1\n",
            "Look again at Questions 4-6.\n",
            "Page number: nan\n",
            "\n",
            "\n",
            "Score: 0.5271\n",
            "Text:\n",
            "50                   Reading skills       3.3 Look at the sentence completion\n",
            "task below. Find words in the   passage in 3.2 that are paraphrases of the\n",
            "underlined words.       Choose NO MORE THAN THREE WORDS from the passage for\n",
            "each answer.     1 Two ingredients used to make paint found in the cave were\n",
            ".....and......     2 Two examples of to£i§ used to make the paint that were\n",
            "found in the cave     are...and...       3 The scientists used the.     QUt how\n",
            "the paint was made       .... on the equipment to help work       3.4 Carefully\n",
            "read the text, before and after the words you have   found. Then complete\n",
            "Questions 1-3.     Flow-chart and Note completion tasks     A flow chart is a\n",
            "diagram iliai shows ilie sequence of events in a   process. In flow-chart\n",
            "completion questions, the information may   not be presented in the same order\n",
            "as in the passage.     3.5 Study the flow-chart completion task below. For\n",
            "Questions 1-6,   decide what type of information you need to find.\n",
            "Page number: nan\n",
            "\n",
            "\n",
            "Score: 0.5006\n",
            "Text:\n",
            "3.3 Read statements 4-8, then underline ihc relevant parts in the text. Arc the\n",
            "statements True, False or Nci Given?     4 Atiania has experienced more dramatic\n",
            "weather change than other areas of the US.     5 Roofs that are dark in colour\n",
            "help address the issue of Urban Heat islands.     6 Singapore's Supenrees are\n",
            "made entirely from natural materials.     7 The designers of the Supertrees\n",
            "originally planned to plant very tall trees.     8 The Superirees require\n",
            "regular maintenance.       3.4 Read statements 1-8 again and correct any that\n",
            "were false.       58\n",
            "information     In this unit you will practise:     • identifying types of\n",
            "information     • locating and matching information     • connecting ideas     •\n",
            "matching sentence endings     • matching information     v**' vv w E1- + 'f m\n",
            "t Identifying types of information     For matching information tasks, you need\n",
            "to locate ail idea or piece of   information in the texi and match it to a\n",
            "phrase that accurately describes it.       1.1 Read the extracts from two\n",
            "separate paragraphs of a Reading   passage.\n",
            "Page number: nan\n",
            "\n",
            "\n",
            "Score: 0.4489\n",
            "Text:\n",
            "1 neon - ,Sant £ flirty tlinf is created fiij jchnf     Choose ONE WORD ONLY\n",
            "from th$ passage for each answer.     How pigment was made in ancient times\n",
            "Test Tip Make sure   you read the whole   passage so that you can   locate any\n",
            "key words   and paraphrases from   the questions. Take   highlighter pens into\n",
            "the exam with you. Use   a different colour for   each task, to highlight\n",
            "important parts of the   text This will help save   time when checking   I\n",
            "answers,         51\n",
            "Reading skills       3.6 Look ai the two Reading passages in i.l and 3,2. Which\n",
            "words   or ideas are paraphrases of the underlined words in the flow   chart?\n",
            "Highlight the pans you need u> read in detail.     3.7 Carefully read the\n",
            "passages in I.l and 3.2 and complete the flow   chart. Make sure you use ONE\n",
            "WORD ONLV from the passages.     Note completion tasks are similar to flow-chart\n",
            "completion, but may   cover a larger pan of the Reading passage. Again, the\n",
            "Information may   not he presented in the same order as the information in the\n",
            "passage.\n",
            "Page number: nan\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functionizing our semantic search pipeline"
      ],
      "metadata": {
        "id": "HPsipGs2VDP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_resources(query: str,\n",
        "                                embeddings: torch.tensor,\n",
        "                                model: SentenceTransformer=embedding_model,\n",
        "                                n_resources_to_return: int=5,\n",
        "                                print_time: bool=True):\n",
        "    \"\"\"\n",
        "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Embed the query\n",
        "    query_embedding = model.encode(query,\n",
        "                                   convert_to_tensor=True)\n",
        "\n",
        "    # Get dot product scores on embeddings\n",
        "    start_time = timer()\n",
        "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
        "    end_time = timer()\n",
        "\n",
        "    if print_time:\n",
        "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "    scores, indices = torch.topk(input=dot_scores,\n",
        "                                 k=n_resources_to_return)\n",
        "\n",
        "    return scores, indices\n",
        "\n",
        "def print_top_results_and_scores(query: str,\n",
        "                                 embeddings: torch.tensor,\n",
        "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
        "                                 n_resources_to_return: int=5):\n",
        "    \"\"\"\n",
        "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
        "\n",
        "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
        "    \"\"\"\n",
        "\n",
        "    scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                                  embeddings=embeddings,\n",
        "                                                  n_resources_to_return=n_resources_to_return)\n",
        "\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    print(\"Results:\")\n",
        "    # Loop through zipped together scores and indicies\n",
        "    for score, index in zip(scores, indices):\n",
        "        print(f\"Score: {score:.4f}\")\n",
        "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
        "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
        "        # Print the page number too so we can reference the textbook further and check the results\n",
        "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "1E9TveJnVCFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"listerning skills\"\n",
        "\n",
        "# Get just the scores and indices of top related results\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "scores, indices"
      ],
      "metadata": {
        "id": "bxdP6qeXVFDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5837e7b-37ae-4502-d87d-c57bb2b9903f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Time taken to get scores on 30 embeddings: 0.00007 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.3542, 0.3339, 0.3295, 0.2792, 0.2771], device='cuda:0'),\n",
              " tensor([ 4, 23,  2,  0,  5], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}